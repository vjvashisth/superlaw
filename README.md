# GAL-RAG-System

A modular document parsing and semantic search pipeline using Unstructured.io, OpenAI embeddings, and FAISS â€” with a Streamlit interface for querying.

---

## ğŸ“¦ Features

- Parse PDF, DOCX, PPTX, TXT, HTML, XLSX and CSV using [Unstructured.io](https://github.com/Unstructured-IO/unstructured)
- Chunk and normalize text content
- Generate embeddings using OpenAI `text-embedding-3-small`
- Store in a FAISS vector index for semantic retrieval
- Query through a clean Streamlit UI
- Fully Dockerized for deployment
- Includes examples and test suite

---

## ğŸ§­ Project Structure

```bash
GAL-RAG-System/
â”œâ”€â”€ config/                          # Configuration files (YAML)
â”‚   â””â”€â”€ config.yaml
â”œâ”€â”€ examples/                        # Sample input and expected output formats
â”‚   â”œâ”€â”€ sample_input.txt
â”‚   â””â”€â”€ sample_output.json
â”œâ”€â”€ outputs/                         # Parsed + chunked output files (grouped by date)
â”‚   â””â”€â”€ 2025-05-18/
â”‚       â””â”€â”€ <filename>.json
â”œâ”€â”€ samples/                         # Input documents (PDF, DOCX, PPTX, etc.)
â”‚   â””â”€â”€ example.pdf
â”œâ”€â”€ src/                             # Core pipeline code
â”‚   â”œâ”€â”€ app.py                       # Streamlit semantic search interface
â”‚   â”œâ”€â”€ main.py                      # End-to-end document parsing + chunking
â”‚   â”œâ”€â”€ embed_and_store.py           # OpenAI embedding + FAISS indexing
â”‚   â”œâ”€â”€ parser_unstructured.py       # Parser using Unstructured.io
â”‚   â”œâ”€â”€ parser_docetl.py             # Deprecated in favor of Unstructured-based pipeline
â”‚   â”œâ”€â”€ chunking.py                  # Custom chunking logic
â”‚   â”œâ”€â”€ file_utils.py                # File loader, MIME checker, folder setup
â”‚   â”œâ”€â”€ metadata_extractor.py        # Metadata extractor from parsed output
â”‚   â””â”€â”€ schema.py                    # Output formatter + JSON writer
â”œâ”€â”€ tests/                           # Unit tests for core modules
â”‚   â””â”€â”€ test_chunking.py
â”œâ”€â”€ vector_index/                   # FAISS vector DB + metadata (generated)
â”‚   â”œâ”€â”€ faiss.index
â”‚   â””â”€â”€ metadata.json
â”œâ”€â”€ Dockerfile                       # Container setup for reproducible runs
â”œâ”€â”€ requirements.txt                 # Python dependencies
â””â”€â”€ README.md                        # Project documentation

````

---

## ğŸš€ Quickstart

### 1. Clone the Repo

```bash
git clone https://github.com/GALBASE/GAL-RAG-System.git
cd GAL-RAG-System
```

### 2. Install Requirements (Locally)

```bash
pip install -r requirements.txt
```

### 3. Export Your OpenAI Key

```bash
export OPENAI_API_KEY=sk-xxxxxxxxxxxxxxxx
```

---

## ğŸ”„ Running the Pipeline

### â¤ Step 1: Parse and Chunk

```bash
python src/main.py
```

### â¤ Step 2: Generate Embeddings + Index

```bash
python src/embed_and_store.py
```

### â¤ Step 3: Launch the Streamlit App

```bash
streamlit run src/app.py
```

Then open: [http://localhost:8501](http://localhost:8501)

---

## ğŸ³ Run with Docker

### Build the Image

```bash
docker build -t gal-rag-system .
```

### Run the App with Mounted FAISS Index

```bash
docker run -p 8501:8501 \
  -e OPENAI_API_KEY=sk-xxxxxxxxxxxxxxxx \
  -v $PWD/vector_index:/app/vector_index \
  gal-rag-system
```

> ğŸ” Use `-v $PWD/outputs:/app/outputs` if embedding in-container is also needed.

---

## ğŸ“ Examples

* `examples/sample_input.txt` â†’ describes input expectations
* `examples/sample_output.json` â†’ shows normalized output format

---

## ğŸ§ª Run Tests

```bash
pip install pytest
pytest tests/
```

---

## ğŸ” Environment Variables

| Variable         | Description                                  |
| ---------------- | -------------------------------------------- |
| `OPENAI_API_KEY` | Your OpenAI API key (required for embedding) |

---

## ğŸ“ƒ License

MIT License